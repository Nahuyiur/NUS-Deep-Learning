{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ea75861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, random\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ce52e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess(img_path, img_size=300):\n",
    "    img = image.load_img(img_path, target_size=(img_size, img_size))\n",
    "    arr = image.img_to_array(img)\n",
    "    arr = preprocess_input(arr)\n",
    "    return tf.expand_dims(arr, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aff7a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_random_samples(model_path, val_dir, k=100, img_size=300):\n",
    "    \"\"\"\n",
    "    éšæœºæŠ½å– k å¼ éªŒè¯é›†å›¾ç‰‡ï¼Œæ±‡æ€»æ¯ä¸ªçœŸå®ç±»åˆ«è¢«é¢„æµ‹æˆå„ç±»åˆ«çš„è®¡æ•°ï¼Œ\n",
    "    å¹¶æ‰“å°æ¯ç±»æ ·æœ¬æ•°ã€æ¯ç±»æ­£ç¡®ç‡ã€è¯¯åˆ¤å»å‘ã€‚\n",
    "    \"\"\"\n",
    "    # 1) å–å¾—ç±»åˆ«é¡ºåº\n",
    "    ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        os.path.join(val_dir, '..', 'train'),\n",
    "        image_size=(img_size, img_size), batch_size=32, shuffle=False)\n",
    "    class_names = ds.class_names\n",
    "    name2label  = {n:i for i,n in enumerate(class_names)}\n",
    "    n_classes   = len(class_names)\n",
    "\n",
    "    # 2) æ”¶é›†éªŒè¯é›†ä¸­æ‰€æœ‰å›¾ç‰‡(è·¯å¾„, çœŸå®æ ‡ç­¾)\n",
    "    all_imgs = []\n",
    "    for cls in class_names:\n",
    "        for p in (Path(val_dir)/cls).glob('*'):\n",
    "            if p.suffix.lower() in ['.jpg','.jpeg','.png','.bmp','.gif']:\n",
    "                all_imgs.append((str(p), name2label[cls]))\n",
    "\n",
    "    random.shuffle(all_imgs)\n",
    "    samples = all_imgs[:k]\n",
    "\n",
    "    # 3) é¢„æµ‹\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    conf_mat = np.zeros((n_classes, n_classes), dtype=int)   # [çœŸå®, é¢„æµ‹]\n",
    "\n",
    "    for p, true_lab in samples:\n",
    "        pred = np.argmax(model.predict(load_and_preprocess(p, img_size))[0])\n",
    "        conf_mat[true_lab, pred] += 1\n",
    "\n",
    "    # 4) æ±‡æ€» & æ‰“å°\n",
    "    print(f\"ğŸ¯ éšæœºæŠ½å– {k} å¼ éªŒè¯é›†å›¾ç‰‡åçš„ç»Ÿè®¡ï¼š\\n\")\n",
    "    for i, cls in enumerate(class_names):\n",
    "        row = conf_mat[i]\n",
    "        total   = row.sum()\n",
    "        correct = row[i]\n",
    "        if total == 0:\n",
    "            print(f\"- {cls:<15}: æ ·æœ¬ 0\")\n",
    "            continue\n",
    "        acc = correct / total\n",
    "        # æ„é€ â€œè¢«é¢„æµ‹æˆ X çš„å¼ æ•°â€æ‘˜è¦\n",
    "        miss = {class_names[j]:row[j] for j in range(n_classes) if j!=i and row[j]>0}\n",
    "        miss_str = \", \".join([f\"{n}:{c}\" for n,c in miss.items()]) if miss else \"â€”\"\n",
    "        print(f\"- {cls:<15}: æ ·æœ¬ {total:<3}  æ­£ç¡® {correct:<3}  å‡†ç¡®ç‡ {acc:6.1%}  è¯¯åˆ¤â†’ {miss_str}\")\n",
    "\n",
    "    overall_acc = np.trace(conf_mat) / k\n",
    "    print(f\"\\nâœ… æ€»ä½“å‡†ç¡®ç‡ï¼š{overall_acc:.2%}\")\n",
    "    return conf_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bca3f5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1306 files belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-03 21:26:35.657426: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "ğŸ¯ éšæœºæŠ½å– 30 å¼ éªŒè¯é›†å›¾ç‰‡åçš„ç»Ÿè®¡ï¼š\n",
      "\n",
      "- Pallas cats    : æ ·æœ¬ 7    æ­£ç¡® 7    å‡†ç¡®ç‡ 100.0%  è¯¯åˆ¤â†’ â€”\n",
      "- Persian cats   : æ ·æœ¬ 6    æ­£ç¡® 6    å‡†ç¡®ç‡ 100.0%  è¯¯åˆ¤â†’ â€”\n",
      "- Ragdolls       : æ ·æœ¬ 6    æ­£ç¡® 6    å‡†ç¡®ç‡ 100.0%  è¯¯åˆ¤â†’ â€”\n",
      "- Singapura cats : æ ·æœ¬ 7    æ­£ç¡® 7    å‡†ç¡®ç‡ 100.0%  è¯¯åˆ¤â†’ â€”\n",
      "- Sphynx cats    : æ ·æœ¬ 4    æ­£ç¡® 4    å‡†ç¡®ç‡ 100.0%  è¯¯åˆ¤â†’ â€”\n",
      "\n",
      "âœ… æ€»ä½“å‡†ç¡®ç‡ï¼š100.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7, 0, 0, 0, 0],\n",
       "       [0, 6, 0, 0, 0],\n",
       "       [0, 0, 6, 0, 0],\n",
       "       [0, 0, 0, 7, 0],\n",
       "       [0, 0, 0, 0, 4]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------- è°ƒç”¨ç¤ºä¾‹ -----------\n",
    "model_path = 'final_model_full.h5'               # ä½ çš„æ¨¡å‹\n",
    "val_dir    = 'DL_Classify/validation'            # validation æ ¹ç›®å½•\n",
    "k          = 30                                  # æƒ³æŠ½å¤šå°‘å¼ \n",
    "\n",
    "evaluate_random_samples(model_path, val_dir, k)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
