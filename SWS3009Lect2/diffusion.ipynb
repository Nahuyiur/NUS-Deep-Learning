{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec0056a8",
   "metadata": {},
   "source": [
    "# Diffusion Model on 16x16 MNIST with UNet and Cosine Noise Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b75f9bf-2151-42d3-bb66-7689fa990b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers, models, losses, callbacks, datasets, metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import smart_resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "655aeb07-35d6-4780-b20d-8141f6661a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 16\n",
    "NUM_CHANNELS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3158130a-c602-46b1-8411-c877c9ee0514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "(x_train, _), (_, _) = datasets.mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "\n",
    "# Resize and convert to numpy array, rescale from 0 to 1\n",
    "x_train = np.array([smart_resize(img, (IMG_SIZE, IMG_SIZE)) for img in x_train])/255.0\n",
    "\n",
    "# Rescale \n",
    "x_train = (x_train.astype(np.float32) - 0.5) * 2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e04c7c-9dbf-4a3e-8159-fa27c784504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diffusion(models.Model):\n",
    "    def __init__(self, img_size=16, img_channels=1, timesteps=200, time_emb_dim=64):\n",
    "        super(Diffusion, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.img_channels = img_channels\n",
    "        self.timesteps = timesteps\n",
    "        self.emb_dim = time_emb_dim\n",
    "        self.total_loss = metrics.Mean(name='total_loss')\n",
    "        self.unet = self.make_unet()\n",
    "        self.beta, self.alpha, self.alpha_hat = self.cosine_beta_schedule()\n",
    "        \n",
    "    def conv_block(self, x, filters, kernel_size=3, activation='relu'):\n",
    "        x = layers.Conv2D(filters, kernel_size, padding='same', activation=activation)(x)\n",
    "        x = layers.Conv2D(filters, kernel_size, padding='same', activation=activation)(x)\n",
    "        return x\n",
    "\n",
    "    def make_unet(self):\n",
    "        image_input = layers.Input(shape=(self.img_size, self.img_size, self.img_channels))\n",
    "        t_input = layers.Input(shape=(), dtype=tf.int32)\n",
    "    \n",
    "        # Timestep embedding\n",
    "        t_emb = self.get_timestep_embedding(t_input)\n",
    "        t_emb = layers.Dense(128, activation='relu')(t_emb)\n",
    "        t_emb = layers.Dense(self.img_size * self.img_size * 32)(t_emb)\n",
    "        t_emb = layers.Reshape((self.img_size, self.img_size, 32))(t_emb)\n",
    "    \n",
    "        x = layers.Concatenate()([image_input, t_emb])\n",
    "    \n",
    "        # Downsampling\n",
    "        c1 = self.conv_block(x, 32)\n",
    "        p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "        c2 = self.conv_block(p1, 64)\n",
    "        p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "        # Bottleneck\n",
    "        bn = self.conv_block(p2, 128)\n",
    "    \n",
    "        # Upsampling\n",
    "        u1 = layers.UpSampling2D((2, 2))(bn)\n",
    "        u1 = layers.Concatenate()([u1, c2])\n",
    "        c3 = self.conv_block(u1, 64)\n",
    "    \n",
    "        u2 = layers.UpSampling2D((2, 2))(c3)\n",
    "        u2 = layers.Concatenate()([u2, c1])\n",
    "        c4 = self.conv_block(u2, 32)\n",
    "    \n",
    "        output = layers.Conv2D(self.img_channels, 1, padding='same')(c4)\n",
    "    \n",
    "        return models.Model([image_input, t_input], output)\n",
    "\n",
    "    def cosine_beta_schedule(self):\n",
    "        steps = self.timesteps + 1\n",
    "        x = np.linspace(0, self.timesteps, steps)\n",
    "        alphas_cumprod = np.cos(((x / self.timesteps) + 0.008) / (1 + 0.008) * np.pi * 0.5) ** 2\n",
    "        alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "        betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "        beta = np.clip(betas, 0.0001, 0.9999).astype(np.float32)\n",
    "        alpha = 1.0 - beta\n",
    "        alpha_hat = np.cumprod(alpha)\n",
    "        return beta, alpha, alpha_hat\n",
    "\n",
    "    def get_timestep_embedding(self, timesteps):\n",
    "        half_dim = self.emb_dim // 2\n",
    "        emb = np.log(10000) / (half_dim - 1)\n",
    "        emb = tf.cast(timesteps, tf.float32)[:, None] * tf.exp(-emb * tf.range(half_dim, dtype=tf.float32)[None, :])\n",
    "        emb = tf.concat([tf.sin(emb), tf.cos(emb)], axis=-1)\n",
    "        return emb\n",
    "\n",
    "    def add_noise(self, x, t):\n",
    "        noise = tf.random.normal(shape=tf.shape(x))\n",
    "        alpha_hat_t = tf.gather(self.alpha_hat, t)\n",
    "        sqrt_alpha_hat = tf.sqrt(alpha_hat_t)[:, None, None, None]\n",
    "        sqrt_one_minus_alpha_hat = tf.sqrt(1.0 - alpha_hat_t)[:, None, None, None]\n",
    "        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * noise, noise\n",
    "\n",
    "    def compile(self, optimizer, loss):\n",
    "        super().compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.total_loss]\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        x = data[0]\n",
    "\n",
    "        # Make sure x is 4D\n",
    "        if len(x.shape) != 4:\n",
    "            x = tf.expand_dims(x, 0)\n",
    "\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        t = tf.random.uniform((batch_size,), minval=0, maxval=self.timesteps, dtype=tf.int32)\n",
    "        noisy_x, noise = self.add_noise(x, t)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = self.unet([noisy_x, t], training=True)\n",
    "            loss = self.loss_fn(noise, pred)\n",
    "\n",
    "        grads = tape.gradient(loss, self.unet.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.unet.trainable_variables))\n",
    "        self.total_loss.update_state(loss)\n",
    "\n",
    "        return {x.name: x.result() for x in self.metrics}\n",
    "        \n",
    "    def sample(self, n=10):\n",
    "        x = tf.random.normal((n, self.img_size, self.img_size, self.img_channels))\n",
    "        for t in reversed(range(self.timesteps)):\n",
    "            t_tensor = tf.constant([t] * n, dtype=tf.int32)\n",
    "            alpha_t = tf.constant(self.alpha[t], dtype=tf.float32)\n",
    "            alpha_hat_t = tf.constant(self.alpha_hat[t], dtype=tf.float32)\n",
    "            beta_t = tf.constant(self.beta[t], dtype=tf.float32)\n",
    "            pred_noise = self.unet([x, t_tensor], training=False)\n",
    "            coef1 = 1 / tf.sqrt(alpha_t)\n",
    "            coef2 = (1 - alpha_t) / tf.sqrt(1 - alpha_hat_t)\n",
    "            mean = coef1 * (x - coef2 * pred_noise)\n",
    "            if t > 0:\n",
    "                z = tf.random.normal(shape=x.shape)\n",
    "                x = mean + tf.sqrt(beta_t) * z\n",
    "            else:\n",
    "                x = mean\n",
    "        return (x + 1.0) / 2.0  # Rescale to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3d06aaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m diffusion \u001b[38;5;241m=\u001b[39m Diffusion()\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optimizers\u001b[38;5;241m.\u001b[39mlegacy\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m      3\u001b[0m mse \u001b[38;5;241m=\u001b[39m losses\u001b[38;5;241m.\u001b[39mMeanSquaredError()\n",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m, in \u001b[0;36mDiffusion.__init__\u001b[0;34m(self, img_size, img_channels, timesteps, time_emb_dim)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb_dim \u001b[38;5;241m=\u001b[39m time_emb_dim\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_loss \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mMean(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_unet()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcosine_beta_schedule()\n",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m, in \u001b[0;36mDiffusion.make_unet\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m t_input \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Timestep embedding\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m t_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_timestep_embedding(t_input)\n\u001b[1;32m     23\u001b[0m t_emb \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(t_emb)\n\u001b[1;32m     24\u001b[0m t_emb \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m32\u001b[39m)(t_emb)\n",
      "Cell \u001b[0;32mIn[4], line 66\u001b[0m, in \u001b[0;36mDiffusion.get_timestep_embedding\u001b[0;34m(self, timesteps)\u001b[0m\n\u001b[1;32m     64\u001b[0m half_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb_dim \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     65\u001b[0m emb \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m10000\u001b[39m) \u001b[38;5;241m/\u001b[39m (half_dim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m emb \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(timesteps, tf\u001b[38;5;241m.\u001b[39mfloat32)[:, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m tf\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39memb \u001b[38;5;241m*\u001b[39m tf\u001b[38;5;241m.\u001b[39mrange(half_dim, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)[\u001b[38;5;28;01mNone\u001b[39;00m, :])\n\u001b[1;32m     67\u001b[0m emb \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat([tf\u001b[38;5;241m.\u001b[39msin(emb), tf\u001b[38;5;241m.\u001b[39mcos(emb)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m emb\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/backend/common/keras_tensor.py:156\u001b[0m, in \u001b[0;36mKerasTensor.__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused when constructing Keras Functional models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand `keras.ops`). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are likely doing something like:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = Input(...)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_fn(x)  # Invalid.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MyLayer(Layer):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def call(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return tf_fn(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = MyLayer()(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.ops`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "diffusion = Diffusion()\n",
    "optimizer = optimizers.legacy.Adam(1e-4)\n",
    "mse = losses.MeanSquaredError()\n",
    "diffusion.compile(optimizer, mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88511d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 3000\n",
    "\n",
    "diffusion.fit(x_train, epochs = epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc40e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = diffusion.sample()\n",
    "\n",
    "plt.figure(figsize=(10, 2))\n",
    "for i in range(samples.shape[0]):\n",
    "    plt.subplot(1, samples.shape[0], i + 1)\n",
    "    plt.imshow(samples[i, ..., 0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Generated Samples')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5244a44-ace1-4bea-ae88-c718b9d1ddc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
